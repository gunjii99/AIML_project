{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers\n",
    "%pip install torch\n",
    "%pip install PyTorch\n",
    "%pip install import_ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [user_id, text]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import cleanData as datab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"tabularisai/robust-sentiment-analysis\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "        predicted_class = torch.argmax(probabilities, dim=-1).item()\n",
    "        sentiment_map = {\n",
    "            0: \"Very Negative\",\n",
    "            1: \"Negative\",\n",
    "            2: \"Neutral\",\n",
    "            3: \"Positive\",\n",
    "            4: \"Very Positive\"\n",
    "        }\n",
    "        return sentiment_map[predicted_class]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text      sentiment\n",
      "0  Great staff always helps and always nice. Alwa...  Very Positive\n",
      "1  After my ROTD  yesterday of a different Sweet ...        Neutral\n",
      "2  Our family returned for breakfast again this w...       Positive\n",
      "3  If I could give it a zero, I would. I order a ...  Very Negative\n",
      "4  Id you haven't been to the Smoothie King cente...       Positive\n"
     ]
    }
   ],
   "source": [
    "datab.dataset_df[\"sentiment\"] = datab.dataset_df[\"text\"].apply(predict_sentiment)\n",
    "print(datab.dataset_df[[\"text\", \"sentiment\"]].head())\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "datab.dataset_df.to_json(\"hugging_face_sentiment_analysis.json\", orient=\"records\", lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping from sentiment labels to scores\n",
    "sentiment_score_map = {\n",
    "    \"Very Negative\": 1,\n",
    "    \"Negative\": 2,\n",
    "    \"Neutral\": 3,\n",
    "    \"Positive\": 4,\n",
    "    \"Very Positive\": 5\n",
    "}\n",
    "\n",
    "# Apply the mapping to create a new column\n",
    "datab.dataset_df[\"sentiment_score\"] = datab.dataset_df[\"sentiment\"].map(sentiment_score_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "datab.dataset_df.to_json(\"full_sentiment_data_with_scores.json\", orient=\"records\", lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Match Accuracy: 0.47183465879457454\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(datab.dataset_df[\"stars\"].astype(int),\n",
    "                          datab.dataset_df[\"sentiment_score\"].astype(int))\n",
    "print(\"Exact Match Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.6702\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Compute MAE\n",
    "mae = mean_absolute_error(datab.dataset_df[\"stars\"], datab.dataset_df[\"sentiment_score\"])\n",
    "print(f\"Mean Absolute Error: {mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_3_scale(score):\n",
    "    if score in [1, 2]:\n",
    "        return 1\n",
    "    elif score == 3:\n",
    "        return 2\n",
    "    elif score in [4, 5]:\n",
    "        return 3\n",
    "\n",
    "# Apply to both columns\n",
    "datab.dataset_df[\"stars_3_scale\"] = datab.dataset_df[\"stars\"].apply(convert_to_3_scale)\n",
    "datab.dataset_df[\"sentiment_score_3_scale\"] = datab.dataset_df[\"sentiment_score\"].apply(convert_to_3_scale)\n",
    "datab.dataset_df.to_json(\"updated_sentiment_data_3_scale.json\", orient=\"records\", lines=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Match Accuracy: 0.7091632379660278\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(datab.dataset_df[\"stars_3_scale\"].astype(int),\n",
    "                          datab.dataset_df[\"sentiment_score_3_scale\"].astype(int))\n",
    "print(\"Exact Match Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.3119\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Compute MAE\n",
    "mae = mean_absolute_error(datab.dataset_df[\"stars_3_scale\"], datab.dataset_df[\"sentiment_score_3_scale\"])\n",
    "print(f\"Mean Absolute Error: {mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  stars  sentiment_score  \\\n",
      "0  Great staff always helps and always nice. Alwa...    5.0                5   \n",
      "1  After my ROTD  yesterday of a different Sweet ...    4.0                3   \n",
      "2  Our family returned for breakfast again this w...    5.0                4   \n",
      "3  If I could give it a zero, I would. I order a ...    1.0                1   \n",
      "4  Id you haven't been to the Smoothie King cente...    4.0                4   \n",
      "5  Don't know what it is but If my tummy's feelin...    4.0                3   \n",
      "6  Service and management terrible... After messi...    1.0                1   \n",
      "7  Been to this location twice and will never go ...    1.0                3   \n",
      "8  This is one of the busiest Chick fil A's I've ...    5.0                5   \n",
      "9  Had the brisket sandwich with two sides and a ...    5.0                4   \n",
      "\n",
      "   abs_diff  \n",
      "0       0.0  \n",
      "1       1.0  \n",
      "2       1.0  \n",
      "3       0.0  \n",
      "4       0.0  \n",
      "5       1.0  \n",
      "6       0.0  \n",
      "7       2.0  \n",
      "8       0.0  \n",
      "9       1.0  \n"
     ]
    }
   ],
   "source": [
    "# Calculate the absolute difference\n",
    "datab.dataset_df[\"abs_diff\"] = (datab.dataset_df[\"stars\"] - datab.dataset_df[\"sentiment_score\"]).abs()\n",
    "\n",
    "# Print the first few rows showing stars, sentiment_score, and their absolute difference\n",
    "print(datab.dataset_df[[\"text\",\"stars\", \"sentiment_score\", \"abs_diff\"]].head(10))\n",
    "datab.dataset_df.to_json(\"full_sentiment_data_with_scores_and_difference.json\", orient=\"records\", lines=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows\n",
    "filtered_df = datab.dataset_df[datab.dataset_df[\"abs_diff\"] > 1]\n",
    "\n",
    "# Save to JSON\n",
    "filtered_df.to_json(\"filtered_sentiment_mismatches.json\", orient=\"records\", lines=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
