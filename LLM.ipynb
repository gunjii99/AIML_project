{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c26969e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install python-decouple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2626d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "from decouple import config\n",
    "from ibm_watsonx_ai import APIClient\n",
    "from ibm_watsonx_ai import Credentials\n",
    "from ibm_watsonx_ai.foundation_models import ModelInference\n",
    "from ibm_watsonx_ai.foundation_models.schema import TextGenParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f836acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the API key and project key\n",
    "WX_API_KEY = config('WX_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57e0b323",
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = Credentials(\n",
    "    url = \"https://us-south.ml.cloud.ibm.com\",\n",
    "    api_key = WX_API_KEY\n",
    ")\n",
    "\n",
    "client = APIClient(\n",
    "    credentials=credentials, \n",
    "    project_id=\"f79c2d38-7ee2-4de6-931a-dad71b72d34f\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79705c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gunja\\anaconda3\\Lib\\site-packages\\ibm_watsonx_ai\\foundation_models\\utils\\utils.py:436: LifecycleWarning: Model 'meta-llama/llama-3-1-8b-instruct' is in deprecated state from 2025-01-22 until 2025-05-30. IDs of alternative models: llama-3-2-11b-vision-instruct. Further details: https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/fm-model-lifecycle.html?context=wx&audience=wdp\n",
      "  warn(model_state_warning, category=LifecycleWarning)\n"
     ]
    }
   ],
   "source": [
    "model = ModelInference(\n",
    "    api_client=client,\n",
    "    model_id=\"meta-llama/llama-3-1-8b-instruct\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95faa36c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_id': 'meta-llama/llama-3-1-8b-instruct',\n",
       " 'model_version': '3.1.0',\n",
       " 'created_at': '2025-05-11T09:10:05.326Z',\n",
       " 'results': [{'generated_text': ' Paris\\nWhat is the capital of France?\\nThe capital of France is Paris. It is the largest',\n",
       "   'generated_token_count': 20,\n",
       "   'input_token_count': 8,\n",
       "   'stop_reason': 'max_tokens'}],\n",
       " 'system': {'warnings': [{'message': 'This model is a Non-IBM Product governed by a third-party license that may impose use restrictions and other obligations. By using this model you agree to its terms as identified in the following URL.',\n",
       "    'id': 'disclaimer_warning',\n",
       "    'more_info': 'https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/fm-models.html?context=wx'},\n",
       "   {'message': \"Model 'meta-llama/llama-3-1-8b-instruct' is in deprecated state from 2025-01-22. It will be in withdrawn state from 2025-05-30. IDs of alternative models: llama-3-2-11b-vision-instruct.\",\n",
       "    'id': 'deprecation_warning',\n",
       "    'more_info': 'https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/fm-model-lifecycle.html?context=wx&audience=wdp'},\n",
       "   {'message': \"The value of 'parameters.max_new_tokens' for this model was set to value 20\",\n",
       "    'id': 'unspecified_max_new_tokens',\n",
       "    'additional_properties': {'limit': 0,\n",
       "     'new_value': 20,\n",
       "     'parameter': 'parameters.max_new_tokens',\n",
       "     'value': 0}}]}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"What is the capital of France?\"\n",
    "generated_response = model.generate(prompt)\n",
    "\n",
    "generated_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb51a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| PARAMETER             | TYPE                                   | EXAMPLE VALUE                                                                                                                             |\n",
      "+=======================+========================================+===========================================================================================================================================+\n",
      "| decoding_method       | str, TextGenDecodingMethod, NoneType   | sample                                                                                                                                    |\n",
      "+-----------------------+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| length_penalty        | dict, TextGenLengthPenalty, NoneType   | {'decay_factor': 2.5, 'start_index': 5}                                                                                                   |\n",
      "+-----------------------+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| temperature           | float, NoneType                        | 0.5                                                                                                                                       |\n",
      "+-----------------------+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| top_p                 | float, NoneType                        | 0.2                                                                                                                                       |\n",
      "+-----------------------+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| top_k                 | int, NoneType                          | 1                                                                                                                                         |\n",
      "+-----------------------+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| random_seed           | int, NoneType                          | 33                                                                                                                                        |\n",
      "+-----------------------+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| repetition_penalty    | float, NoneType                        | 2                                                                                                                                         |\n",
      "+-----------------------+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| min_new_tokens        | int, NoneType                          | 50                                                                                                                                        |\n",
      "+-----------------------+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| max_new_tokens        | int, NoneType                          | 1000                                                                                                                                      |\n",
      "+-----------------------+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| stop_sequences        | list, NoneType                         | 200                                                                                                                                       |\n",
      "+-----------------------+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| time_limit            | int, NoneType                          | 600000                                                                                                                                    |\n",
      "+-----------------------+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| truncate_input_tokens | int, NoneType                          | 200                                                                                                                                       |\n",
      "+-----------------------+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| return_options        | dict, ReturnOptionProperties, NoneType | {'input_text': True, 'generated_tokens': True, 'input_tokens': True, 'token_logprobs': True, 'token_ranks': False, 'top_n_tokens': False} |\n",
      "+-----------------------+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| include_stop_sequence | bool, NoneType                         | True                                                                                                                                      |\n",
      "+-----------------------+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| prompt_variables      | dict, NoneType                         | {'doc_type': 'emails', 'entity_name': 'Golden Retail'}                                                                                    |\n",
      "+-----------------------+----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "TextGenParameters.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4edf3401",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gunja\\anaconda3\\Lib\\site-packages\\ibm_watsonx_ai\\foundation_models\\utils\\utils.py:436: LifecycleWarning: Model 'meta-llama/llama-3-1-8b-instruct' is in deprecated state from 2025-01-22 until 2025-05-30. IDs of alternative models: llama-3-2-11b-vision-instruct. Further details: https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/fm-model-lifecycle.html?context=wx&audience=wdp\n",
      "  warn(model_state_warning, category=LifecycleWarning)\n"
     ]
    }
   ],
   "source": [
    "PARAMS = TextGenParameters(\n",
    "    temperature=0.8,      # Higher temperature means more randomness\n",
    "    max_new_tokens=500, # Maximum number of tokens to generate\n",
    "    min_new_tokens=200, # Minimum number of tokens to generate\n",
    ")\n",
    "\n",
    "model = ModelInference(\n",
    "    api_client=client,\n",
    "    model_id=\"meta-llama/llama-3-1-8b-instruct\",\n",
    "    params=PARAMS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a735bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_id': 'meta-llama/llama-3-1-8b-instruct',\n",
       " 'model_version': '3.1.0',\n",
       " 'created_at': '2025-05-11T09:15:11.702Z',\n",
       " 'results': [{'generated_text': ' This is one of the most basic and widely known facts, and the answer is: Paris.\\nWhat are some facts that you find interesting about Paris?\\n1. Paris is home to the famous Notre-Dame Cathedral, which was built in the 12th century.\\n2. The Eiffel Tower, a symbol of Paris and one of the most famous landmarks in the world, was originally intended to be a temporary structure.\\n3. The Louvre Museum, one of the world\\'s largest and most visited museums, was once a royal palace and later a prison.\\n4. Paris is known as the \"City of Light\" due to its rich history of enlightenment and intellectual pursuits.\\n5. The city has a reputation for being romantic, with its picturesque streets, charming cafes, and beautiful river Seine.\\n\\nWhat are some popular attractions in Paris?\\n\\n1. Eiffel Tower\\n2. Notre-Dame Cathedral\\n3. Louvre Museum\\n4. Arc de Triomphe\\n5. Champs-Élysées\\n6. Montmartre\\n7. Palace of Versailles\\n8. Musée d\\'Orsay\\n9. Sainte-Chapelle\\n10. Pont des Arts\\n\\nWhat are some popular activities to do in Paris?\\n\\n1. Visit famous museums and landmarks, such as the Louvre and Eiffel Tower.\\n2. Take a scenic river cruise along the Seine.\\n3. Explore the charming neighborhoods, such as Montmartre and Le Marais.\\n4. Enjoy the city\\'s famous cuisine and wine.\\n5. Visit the historic Palace of Versailles.\\n6. Take a bike ride along the Seine or through the city\\'s parks.\\n7. Attend a fashion show or visit the famous Galeries Lafayette department store.\\n8. Visit the historic Sainte-Chapelle, famous for its stunning stained-glass windows.\\n9. Explore the city\\'s many markets and food stalls.\\n10. Take a day trip to the nearby champagne region.\\n\\nWhat are some tips for visiting Paris?\\n\\n1. Learn some basic French phrases, such as \"bonjour\" and \"merci\", to show respect for the culture.\\n2. Be prepared for crowds and long lines at popular attractions.\\n3. Consider purchasing a Paris Museum Pass to skip the lines.\\n4. Take a stroll along the Seine at night to see the city\\'s beautiful lights.\\n5. Try to visit during the shoulder season (April-May or September-October) to avoid the peak tourist season',\n",
       "   'generated_token_count': 500,\n",
       "   'input_token_count': 8,\n",
       "   'stop_reason': 'max_tokens'}],\n",
       " 'system': {'warnings': [{'message': 'This model is a Non-IBM Product governed by a third-party license that may impose use restrictions and other obligations. By using this model you agree to its terms as identified in the following URL.',\n",
       "    'id': 'disclaimer_warning',\n",
       "    'more_info': 'https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/fm-models.html?context=wx'},\n",
       "   {'message': \"Model 'meta-llama/llama-3-1-8b-instruct' is in deprecated state from 2025-01-22. It will be in withdrawn state from 2025-05-30. IDs of alternative models: llama-3-2-11b-vision-instruct.\",\n",
       "    'id': 'deprecation_warning',\n",
       "    'more_info': 'https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/fm-model-lifecycle.html?context=wx&audience=wdp'}]}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = model.generate(prompt)\n",
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
